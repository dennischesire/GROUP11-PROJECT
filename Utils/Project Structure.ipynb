{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b0ffbf-c117-4904-ab5e-4c8d7e9c5d66",
   "metadata": {},
   "source": [
    "# **CRISP-DM Framework for Twitter Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47d4a8-e75d-4b35-9013-a2621770c4dc",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9405f031-fbba-4188-a78a-4d1c591fb210",
   "metadata": {},
   "source": [
    "**Goal:** Define the problem, stakeholder, and value proposition in simple terms.\n",
    "\n",
    "*   **Stakeholder:** **Product Manager at Apple** (You can choose Google, but pick one for focus).\n",
    "*   **Real-World Problem:** The Product Manager needs a fast, scalable way to monitor public sentiment about their latest product (e.g., a new iPhone or iOS update) on Twitter. Manual reading of thousands of tweets is impossible.\n",
    "*   **Project Value:** Build a proof-of-concept model that automatically classifies tweets as **Positive, Negative, or Neutral**. This allows the stakeholder to:\n",
    "    *   Quickly identify and address negative feedback (customer service issues, bugs).\n",
    "    *   Gauge positive reception for marketing campaigns.\n",
    "    *   Track sentiment trends over time.\n",
    "\n",
    "**Deliverable:** This will form the **Introduction** of your notebook and presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297d2f19-5ecd-46aa-8113-6b6367bef5b3",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4102b2-1fdc-4c52-bd26-ba6c3bce3691",
   "metadata": {},
   "source": [
    "**Goal:** Load, explore, and describe the data to show its suitability.\n",
    "\n",
    "*   **Load Data:** Load the `twitter.csv` (or similar) from data.world.\n",
    "*   **Initial Exploration:**\n",
    "    *   Check shape (rows, columns).\n",
    "    *   Check for missing values (especially in the `text` and `sentiment` columns).\n",
    "    *   Identify the features (`text`) and the target (`sentiment`).\n",
    "*   **Descriptive Statistics & EDA:**\n",
    "    *   **Class Distribution:** Plot a bar chart of the sentiment labels. **Crucially, note the imbalance** (e.g., more neutral tweets). This is a key data limitation.\n",
    "    *   **Text Statistics:** Calculate and discuss average tweet length, unique words, etc.\n",
    "    *   **Sample Inspection:** Manually read a sample of tweets for each sentiment to build intuition.\n",
    "\n",
    "**Deliverable:** A \"Data Understanding\" section in your notebook with charts and commentary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9a287-6cd9-4ff1-b16f-22faa3de073e",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3c21f7-536f-4a5e-a803-b76f1fcbcb19",
   "metadata": {},
   "source": [
    "**Goal:** Clean the text data and prepare it for modeling in a reproducible, justifiable way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa41c40-fec0-4052-a035-8794a1222681",
   "metadata": {},
   "source": [
    "## Text Preprocessing (Create a function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc2661-6fe1-4623-9186-32ba8b88479c",
   "metadata": {},
   "source": [
    " **Justification:** We clean the text to reduce noise and help the model focus on meaningful words.\n",
    "   *  **Steps:**\n",
    "        * **Lowercase:** `\"Apple\"` and `\"apple\"` should be the same.\n",
    "        * **Remove URLs, User Mentions, and Hashtags:** These are often unique and don't carry general sentiment meaning. (Alternatively, you could replace them with placeholders like `[URL]`).\n",
    "        * **Remove Punctuation and Numbers:** Simplifies the text.\n",
    "        * **Tokenization:** Split text into individual words.\n",
    "        * **Remove Stopwords** (using `nltk` or `spacy`): Remove common words like \"the\", \"and\" that add little semantic value.\n",
    "        * **Lemmatization** (preferred over stemming): Reduce words to their base form (e.g., \"running\" -> \"run\") using `nltk` or `spacy`. **This is your \"other Python package.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0bf745-beb9-4deb-b95e-e96ae5350d1d",
   "metadata": {},
   "source": [
    "## Target Variable Preparation:\n",
    "-   **Proof-of-Concept Path (Recommended):** Map the sentiment to a **binary** problem first (e.g., drop \"neutral\" tweets). This simplifies the initial model and makes it easier to achieve good performance.\n",
    "-   **Advanced Path:** Keep all three classes (Positive, Negative, Neutral) for a multiclass challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865f103-fb1d-426b-902f-258b064e049c",
   "metadata": {},
   "source": [
    "## Train-Test-Validation Split:\n",
    "- Split data into **Train** (70%), **Validation** (15%), and **Test** (15%) sets. Use `stratify` to preserve the class distribution. **This is your validation strategy.**\n",
    "-  **Justification:** The test set is the final, untouched benchmark. The validation set is used for model selection and hyperparameter tuning during the iterative process.\n",
    "\n",
    "**Deliverable:** A well-documented \"Data Preparation\" section with a preprocessing function. This meets the \"Advanced Data Preparation\" bar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f1856b-26c4-41cd-94cf-30c66a035e2a",
   "metadata": {},
   "source": [
    "# Modeling & Evaluation (Iterative)\n",
    "\n",
    "**Goal:** Build multiple models, compare them, and select a final champion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699bed62-670d-41a7-a24c-6f1162544fe5",
   "metadata": {},
   "source": [
    "We are going to start the modeling phase. We'll proceed step by step, building one model at a time iteratively.\n",
    "\n",
    "Steps for Modeling Phase:\n",
    "\n",
    "1. **Feature Extraction:** Convert the cleaned text into numerical features (e.g., TF-IDF, CountVectorizer)\n",
    "2. **Model Building:** Start with a baseline model and then try more advanced models.\n",
    "3. **Model Evaluation:** Use the validation set to tune hyperparameters and the test set for final evaluation.\n",
    "\n",
    "We are going to use the following models in order:\n",
    "1. **Naive Bayes** (as a baseline)\n",
    "2. **Logistic Regression**\n",
    "3. **Random Forest**\n",
    "\n",
    "- We'll handle class imbalance during model training by using class weights.\n",
    "\n",
    "Let's start with the first model: Naive Bayes.\n",
    "\n",
    "- But first, we need to convert our text data into numerical features. We'll use TF-IDF.\n",
    "\n",
    "- **Note:** We are going to use the Apple-focused dataset for modeling because our stakeholder is interested in Apple products. However, note that the Apple dataset is smaller. We might also consider using the full dataset and then filtering for Apple in production, but for now, let's use the Apple dataset.\n",
    "\n",
    "Steps for Feature Extraction:\n",
    "\n",
    "- We'll use TF-IDF on the 'cleaned_text' column.\n",
    "\n",
    "- We'll fit the TF-IDF vectorizer on the training set and then transform the train, validation, and test sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f72f53-0913-410a-8265-f1b3cda954fe",
   "metadata": {},
   "source": [
    "## Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da9672-5463-4b20-97d6-13b9fe95d01c",
   "metadata": {},
   "source": [
    "**Vectorization:** Convert cleaned text into numbers.\n",
    "- **Model 1:** `CountVectorizer` (Bag-of-Words).\n",
    "- **Model 2:** `TfidfVectorizer` (Term Frequency-Inverse Document Frequency). This often performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303b28b1-df1a-4d8b-97ed-0065fdf1d3ca",
   "metadata": {},
   "source": [
    "## Baseline Model:\n",
    "\n",
    "- **What:** A `DummyClassifier` that predicts the most frequent class.\n",
    "- **Why:** It gives you a performance floor. Any real model must beat this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4234553a-a666-4bb6-8d22-00a3110819a7",
   "metadata": {},
   "source": [
    "## Model Iteration 1: Simple & Fast\n",
    "- **Model:** `MultinomialNB` (Naive Bayes) with `TfidfVectorizer`.\n",
    "- **Evaluation:** Check accuracy, precision, recall, F1-score on the **validation set**. Create a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d61f3-e178-411b-a4b7-a6e6670a5018",
   "metadata": {},
   "source": [
    "## Model Iteration 2: Powerful & Robust\n",
    "- **Model:** `LogisticRegression` with `TfidfVectorizer`.\n",
    "- **Action:** Perform **Hyperparameter Tuning** (e.g., `C`, `max_features` in the vectorizer) using `GridSearchCV` or `RandomizedSearchCV` on the training/validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c750cf-6b0d-4ac1-9467-5cfb80f1cc99",
   "metadata": {},
   "source": [
    "## Model Interpretation (Key for \"Exceeds\"):\n",
    "- **Built-in:** For Logistic Regression, display the most important features (words) for Positive and Negative classes. This is highly explainable.\n",
    "- **Advanced (LIME):** Use the `lime` package to explain *why* a single specific tweet was classified as positive or negative. This is very impressive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9629610-0c2d-417d-b2ea-4465ad7cc839",
   "metadata": {},
   "source": [
    "**Deliverable:** A \"Modeling\" section that clearly shows your iterative process: Baseline -> Model 1 -> Tuned Model 2. This meets and can exceed the \"Advanced ML Modeling\" bar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36270954-468d-4438-b0e4-2306b0d7439a",
   "metadata": {},
   "source": [
    "# Final Evaluation & Conclusion\n",
    "\n",
    "**Goal:** Justify your final model choice and explain its business implications.\n",
    "\n",
    "*   **Final Model Selection:** Choose the best-performing model on the validation set (likely the tuned Logistic Regression).\n",
    "*   **Unbiased Test:** Evaluate **only the final model** on the held-out **test set**. Report the final metrics.\n",
    "*   **Business Interpretation:**\n",
    "    *   \"Our model achieves 85% accuracy on unseen tweets. This means the Product Manager can trust the sentiment labels 85% of the time.\"\n",
    "    *   \"The biggest limitation is class imbalance; the model is better at identifying positive sentiment than negative. In a real-world scenario, we would collect more negative examples.\"\n",
    "    *   **Recommendation:** \"Deploy this model to automatically scan tweets daily and deliver a sentiment dashboard to the product team. This will save dozens of hours of manual work.\"\n",
    "\n",
    "**Deliverable:** The \"Evaluation\" and \"Conclusion\" sections of your notebook and the core of your non-technical presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c8548-7c95-48c0-8070-fcca0dbfcaad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
